---
layout: post
title: "Day 19 â€“ Week-4, Day 5 of CEAMLS "
date: 2025-06-20
author: Sogidechukwu Unegbu
permalink: /day19.html
tags: ["CEAMLS"]

what_i_learned: |  
  Today I learnt:
    - Support Vector Machine(SVM) model was developed in the 1990s by Vladimir Vapnik and his colleagues at AT&T Bell Labs.
    - SVM is inspired by the concept of finding a model that generalizes well, not just fits training data.
    - SVM can be used for both regression and classification.
    - That SVM finds the optimal hyperplane that best separates data into classes with the maximum margin (margin being the distance to nearest data points, called support vectors). It uses kernels to handle non-linear data.
    - Examples of kernels in SVM are Polynomial Kernel, RBF Kernel, Sigmoid Kernel. SOme uses of SVM is text prediction, and image classification.
  
blockers: |
  There were no blockers for today
  
reflection: |
  Today I learned about the Support Vector Machine (SVM), a powerful ML model developed in the 1990s for classification and regression. Its core strength lies in maximizing the margin between classes using support vectors and kernels (like RBF or Polynomial) to handle non-linear data. I now see how SVM applies to real-world tasks like text prediction and image classification, balancing generalization and precision. Although different from the model we would be working with it was still interesting to learn


  
   
---
