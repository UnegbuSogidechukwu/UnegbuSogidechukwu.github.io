---
layout: post
title: "Day 30 – Week-7, Day 1 of CEAMLS "
date: 2025-07-7
author: Sogidechukwu Unegbu
permalink:/day30.html
tags: ["CEAMLS", "Kaggle", "intro to deep learning"]

what_i_learned: |  
  Today I started the Kaggle course **Introduction to deep learning**. While progressing through the course I leearnt the following:
    - A complete round of training data is called **epoch**
    - Optimiziers are algorithms that adjest the weights to minimize the loss
    - Deep learning is an approach to machine learning characterized by deep stacks of computations.
    - the formula for neural newtowrks is the line equation with Weights being the slope and Bias the Y-intercept
    - That activation functions are what allows neural networks to perform more than just linear relationships
    - I finally know what ReLU stands for and it is Rectifier Linear Unit (ReLU)
    - The reason hidden layers are called hidden is because we do not see their outputs.
    - Writing codes for Neaural networks
  I also watched some videos on Neural network, before I started the course
  
blockers: |
  Getting used to the Kaggle platform as it has a lot of stuffs going on.
  
reflection: |
  Today was fruitful as I started the deep learning course helped me understand key concepts like activation functions and hidden layers.It was exciting to finally grasp what ReLU means and how neural networks learn.Writing code made the learning hands-on and clearer as opposed to watching videos.The Kaggle platform felt overwhelming at first, but I’m gradually adjusting, which showed me growth in realtime.
  
  

  
   
---
